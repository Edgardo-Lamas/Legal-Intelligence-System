import '../../styles/pages.css'
import '../../styles/content.css'
import '../../styles/split-layout.css'
import '../../styles/study-page.css'
import { Link } from 'react-router-dom'
import MermaidDiagram from '../../components/Visualizations/MermaidDiagram'
import ModelComparisonChart from '../../components/Visualizations/ModelComparisonChart'

const modelFlowChart = `
graph TD
    Input((Prompt)) --> Box[Caja Negra]
    Box --> Output((Respuesta))
    
    style Input fill:#fff,stroke:#333,stroke-width:2px
    style Box fill:#f9f9fab0,stroke:#d4d4d4
    style Output fill:#fff,stroke:#333,stroke-width:2px
    linkStyle default stroke:#7a7a7a,stroke-width:2px
`

const agentFlowChart = `
graph TD
    Task((Tarea)) --> Think[Razonamiento]
    Think --> Tool[Uso de Herramienta]
    Tool --> Env[Entorno / Web / Docs]
    Env --> Obs[Observaci√≥n de Datos]
    Obs --> Think
    Think --> Action[Acci√≥n Final]

    style Think fill:#e8c078,stroke:#e8c078,color:#1a2234,stroke-width:2px
    style Tool fill:#f9f9fab0,stroke:#d4d4d4
    style Env fill:#f9f9fab0,stroke:#d4d4d4
    style Obs fill:#f9f9fab0,stroke:#d4d4d4
    linkStyle default stroke:#7a7a7a,stroke-width:2px
`

const sections = [
    { id: 'core-concepts', title: 'Core Concepts' },
    { id: 'models-vs-agents', title: 'Modelos vs Agentes' },
    { id: 'chatgpt-vs-gemini', title: 'Comparativa: ChatGPT vs Gemini' },
    { id: 'system-architectures', title: 'System Architectures' },
    { id: 'validation-reasoning', title: 'Validation & Reasoning Criteria' },
    { id: 'risks-errors', title: 'Risks, Errors & Bad Practices' },
]

function Foundations() {
    return (
        <div className="page">
            <header className="page__header">
                <h1 className="page__title">Foundations</h1>
                <p className="page__description">
                    Core conceptual foundations of legal intelligence systems
                </p>
            </header>

            <div className="page__content">
                {/* Section 1: Core Concepts */}
                <section id="core-concepts" className="page__section">
                    <h2 className="page__section-title">Core Concepts</h2>
                    <article className="long-form-content">
                        <h3>¬øQu√© es un LLM (Large Language Model)?</h3>
                        <p>
                            Un LLM es un modelo de inteligencia artificial entrenado con cantidades masivas de texto para generar y comprender lenguaje natural. Funciona prediciendo la siguiente palabra m√°s probable en una secuencia, lo que le permite generar texto coherente, responder preguntas, resumir documentos y m√°s.
                        </p>
                        <p>
                            <strong>Analog√≠a jur√≠dica:</strong> Imagin√° un pasante que ley√≥ millones de documentos legales de todas las jurisdicciones del mundo. Puede redactar, resumir y analizar con fluidez, pero no "sabe" derecho en el sentido de un jurista. Reconoce patrones ling√º√≠sticos, no verdades jur√≠dicas.
                        </p>

                        <h3>Tokens: La unidad b√°sica de procesamiento</h3>
                        <p>
                            Los modelos no procesan palabras, sino <strong>tokens</strong>‚Äîfragmentos de texto que pueden ser palabras completas, partes de palabras o caracteres. En espa√±ol, una palabra promedio equivale a 1.3-1.5 tokens. Un contrato de 10 p√°ginas puede tener entre 8.000 y 12.000 tokens.
                        </p>
                        <p>
                            <strong>Por qu√© importa:</strong> Los modelos tienen l√≠mites de tokens por conversaci√≥n (ventana de contexto). Si tu expediente excede ese l√≠mite, el modelo pierde informaci√≥n del principio‚Äîun problema cr√≠tico para an√°lisis legal completo.
                        </p>

                        <h3>Prompts: El arte de la instrucci√≥n</h3>
                        <p>
                            Un <strong>prompt</strong> es la instrucci√≥n que le das al modelo. La calidad de la respuesta depende directamente de la calidad de tu prompt. Un prompt legal efectivo incluye:
                        </p>
                        <ul>
                            <li><strong>Rol:</strong> "Actu√°s como abogado especialista en derecho laboral argentino"</li>
                            <li><strong>Contexto:</strong> Los hechos relevantes del caso</li>
                            <li><strong>Tarea espec√≠fica:</strong> "Analiz√° si hay despido discriminatorio"</li>
                            <li><strong>Formato de salida:</strong> "Respond√© en formato de dictamen con citas"</li>
                        </ul>

                        <h3>Temperatura: Creatividad vs Precisi√≥n</h3>
                        <p>
                            La <strong>temperatura</strong> es un par√°metro que controla cu√°n "creativo" o "determinista" es el modelo. Va de 0 a 1 (o m√°s en algunos modelos):
                        </p>
                        <ul>
                            <li><strong>Temperatura baja (0-0.3):</strong> Respuestas m√°s predecibles y conservadoras. Ideal para an√°lisis legal donde necesit√°s precisi√≥n.</li>
                            <li><strong>Temperatura alta (0.7-1):</strong> Respuestas m√°s variadas y creativas. √ötil para brainstorming de estrategias.</li>
                        </ul>
                        <p>
                            <strong>Para trabajo jur√≠dico:</strong> Us√° temperatura baja para redacci√≥n de contratos y an√°lisis. Subila solo cuando necesit√©s explorar alternativas argumentales.
                        </p>

                        <h3>Ventana de Contexto: La memoria de trabajo</h3>
                        <p>
                            La <strong>ventana de contexto</strong> es la cantidad m√°xima de tokens que el modelo puede "recordar" en una conversaci√≥n. Es como la capacidad de la mesa de trabajo de un abogado‚Äîsolo cabe cierta cantidad de papeles.
                        </p>
                        <ul>
                            <li><strong>GPT-4:</strong> 128K tokens (~300 p√°ginas)</li>
                            <li><strong>Gemini 1.5 Pro:</strong> 2M tokens (~5.000 p√°ginas)</li>
                            <li><strong>Claude 3:</strong> 200K tokens (~500 p√°ginas)</li>
                        </ul>
                        <p>
                            <strong>Implicancia pr√°ctica:</strong> Para expedientes grandes, Gemini puede procesar todo junto; con GPT-4 necesit√°s fragmentar y usar t√©cnicas de resumen progresivo.
                        </p>
                    </article>
                </section>

                {/* Section 2: Models vs Agents (Visual: Mermaid) */}
                <section id="models-vs-agents" className="page__section section-grid">
                    <div className="section-grid__content">
                        <h2 className="page__section-title">Modelos vs Agentes</h2>
                        <article className="long-form-content">
                            <h3>Definici√≥n T√©cnica</h3>
                            <p>
                                Los modelos de IA generativa (LLMs) son motores probabil√≠sticos entrenados en vastos conjuntos de datos para predecir el siguiente token en una secuencia. Funcionan como repositorios est√°ticos de conocimiento congelado, capaces de reconocimiento de patrones, s√≠ntesis y transformaci√≥n de datos de entrada. Funcionalmente, un modelo es una funci√≥n sin estado: recibe una entrada (prompt), la procesa a trav√©s de sus pesos y produce una salida. No tiene memoria de interacciones pasadas, ni agencia para actuar sobre el mundo, ni capacidad inherente para verificar sus propios resultados contra la realidad externa.
                            </p>
                            <p>
                                Los Agentes de IA, por el contrario, son sistemas din√°micos que encapsulan uno o m√°s modelos dentro de un entorno de ejecuci√≥n. Un agente no es simplemente un generador de texto; es una entidad computacional equipada con herramientas, memoria y un bucle l√≥gico recursivo (a menudo un ciclo de observaci√≥n-pensamiento-acci√≥n). Arquitect√≥nicamente, un agente envuelve al modelo en una capa de control que le permite ejecutar c√≥digo, navegar por la web, consultar bases de datos y mantener el estado a trav√©s de un flujo de trabajo de m√∫ltiples pasos. El modelo es el motor; el agente es el veh√≠culo.
                            </p>

                            <h3>Marco Conceptual</h3>
                            <p>
                                En un Sistema de Inteligencia Legal, modelos y agentes ocupan capas jer√°rquicas distintas. El modelo sirve como el n√∫cleo de razonamiento‚Äîel "cerebro" que procesa tareas ling√º√≠sticas espec√≠ficas como la sumarizaci√≥n o la extracci√≥n de cl√°usulas. El agente sirve como el "trabajador" que crea el flujo de trabajo alrededor de ese razonamiento. Una interfaz de chat simple (ej. ChatGPT mismo) no es un sistema; es una l√≠nea directa y no gestionada hacia el modelo, efectivamente limitada por la ventana de contexto inmediata y la habilidad de prompting del usuario.
                            </p>
                            <p>
                                El verdadero dise√±o de sistemas requiere una capa de orquestaci√≥n donde la decisi√≥n de actuar se separa del acto de generaci√≥n. La orquestaci√≥n implica definir cu√°ndo se debe llamar a un modelo, qu√© contexto se le debe proporcionar y c√≥mo se debe validar su salida antes de activar el siguiente paso. Este cambio de "chatear" a "orquestar" es efectivamente lo que transforma una herramienta casual en un activo profesional robusto.
                            </p>

                            <h3>Implicancias Legales Concretas</h3>
                            <p>
                                En la pr√°ctica legal, esta distinci√≥n es fundacional. Un modelo puede redactar una cl√°usula o resumir una deposici√≥n proporcionada. Sin embargo, un modelo no puede "investigar" un expediente porque la investigaci√≥n es un proceso iterativo de hip√≥tesis, b√∫squeda, lectura y refinamiento. Un sistema basado en agentes puede ser arquitectado para leer una carpeta de PDFs, extraer fechas, construir una l√≠nea de tiempo cronol√≥gica, identificar lagunas en esa l√≠nea de tiempo y marcar activamente discrepancias para revisi√≥n humana.
                            </p>
                            <p>
                                Para la investigaci√≥n judicial, la dependencia de un modelo solo obliga al profesional a curar manualmente cada entrada y salida. Un flujo de trabajo ag√©ntico automatiza la recuperaci√≥n y referencia cruzada de jurisprudencia, asegurando que la cita no sea una alucinaci√≥n, sino recuperada de una base de datos confiable y luego resumida por el modelo. El valor no reside en la generaci√≥n de texto, sino en la confiabilidad del bucle recuperaci√≥n-generaci√≥n.
                            </p>

                            <h3>Nivel Profesional Requerido</h3>
                            <p>
                                Trabajar eficazmente con modelos crudos requiere "ingenier√≠a de prompts"‚Äîla habilidad ling√º√≠stica de coaccionar un motor probabil√≠stico hacia un estado deseado. Esta es una habilidad de nivel usuario. Dise√±ar y operar agentes, sin embargo, requiere "pensamiento sist√©mico"‚Äîla habilidad ingenieril de descomponer una tarea legal compleja en pasos discretos y verificables.
                            </p>
                            <p>
                                Un profesional operando al nivel de agente no solo hace preguntas; dise√±a tuber√≠as (pipelines). Debe entender estructuras de datos, latencia, l√≠mites de ventana de contexto y la l√≥gica de condiciones booleanas (si se encuentra X, hacer Y). Este cambio operativo mueve al profesional legal de consumidor de software a arquitecto de sus propios medios de producci√≥n intelectual.
                            </p>

                            <h3>Riesgos, Errores y Malas Pr√°cticas</h3>
                            <p>
                                El riesgo m√°s significativo en la IA legal es la mentalidad de "seguidor del bot"‚Äîuna sobredependencia de la interfaz de chat como fuente de verdad. Cuando un abogado trata a un modelo como un or√°culo en lugar de un procesador de texto, invita a la alucinaci√≥n y errores l√≥gicos a su trabajo. La "falsa sensaci√≥n de inteligencia" proporcionada por una respuesta fluida a menudo enmascara una falta total de base f√°ctica.
                            </p>
                            <p>
                                En el dise√±o de sistemas, una mala pr√°ctica com√∫n es la falta de pasos de validaci√≥n. A un agente nunca se le debe permitir "decidir" el resultado final de un documento legal sin un paso de revisi√≥n intermedia o una verificaci√≥n de validaci√≥n program√°tica. Automatizar sin supervisi√≥n es negligencia. El sistema debe estar dise√±ado para fallar con gracia y alertar al operador humano cuando la ambig√ºedad es alta, en lugar de inventar confiadamente una falsedad plausible.
                            </p>

                            <h3>Casos de Uso Judiciales y Legales Reales</h3>
                            <p>
                                Considere un caso masivo antimonopolio o una disputa de herencia compleja que involucra docenas de escrituras de propiedad y a√±os de correspondencia. Un abogado humano usando una interfaz de chat est√° abrumado por el volumen; la ventana de contexto del modelo es insuficiente para toda la historia.
                            </p>
                            <p>
                                Un sistema ag√©ntico maneja esto descomponiendo el problema: itera a trav√©s de cada documento, extrae entidades relevantes (nombres, fechas, montos) hacia una base de datos estructurada, y luego usa el modelo para detectar patrones <em>a trav√©s</em> de los datos estructurados. Esto permite la detecci√≥n de contradicciones sutiles‚Äîej., un testigo afirmando estar en la Ciudad A en una fecha cuando un recibo los ubica en la Ciudad B‚Äîque un humano podr√≠a perder en mil p√°ginas de evidencia y un solo prompt de modelo nunca podr√≠a abarcar.
                            </p>

                            <h3>Monetizaci√≥n y Valor Profesional</h3>
                            <p>
                                Entender esta arquitectura permite a una firma pasar de facturar por horas (tiempo dedicado a leer) a facturar por conocimiento (valor de los patrones detectados). Los servicios construidos sobre agentes escalan; un flujo bien dise√±ado corre tan barato en un contrato como lo hace en mil.
                            </p>
                            <p>
                                La propuesta de valor cambia de "tengo un abogado inteligente" a "tengo un sistema propietario para el an√°lisis de riesgos". Este es un diferenciador de mercado defendible. En un mercado saturado con usuarios gen√©ricos de IA, el sistema a medida que integra conocimiento espec√≠fico de la firma y protocolos estrictos de validaci√≥n, se convierte en un activo de alto margen.
                            </p>

                            <h3>Tipo de Especialista que Esto Habilita</h3>
                            <p>
                                Este enfoque de sistemas primero define un nuevo perfil: el Ingeniero Legal o Arquitecto de Sistemas Legales. Este profesional no es meramente un abogado experto en tecnolog√≠a; es un estratega h√≠brido que entiende la naturaleza de la l√≥gica legal y puede traducirla en flujos de trabajo deterministas.
                            </p>
                            <p>
                                A diferencia del "entusiasta de legal tech" que persigue la √∫ltima aplicaci√≥n, este especialista construye infraestructura a largo plazo. Se enfocan en la soberan√≠a de los datos, la auditabilidad y la "industrializaci√≥n" del razonamiento legal. Su trayectoria profesional no est√° ligada a la hora facturable sino a la escalabilidad de los sistemas de inteligencia que despliegan.
                            </p>
                        </article>
                    </div>
                    {/* Visual Sidecar 1 */}
                    <div className="section-grid__visual">
                        <div style={{ display: 'flex', flexDirection: 'column', gap: '2rem', width: '100%' }}>
                            <MermaidDiagram chart={modelFlowChart} title="1. Flujo del Modelo (Est√°tico)" />
                            <MermaidDiagram chart={agentFlowChart} title="2. Flujo del Agente (Din√°mico)" />
                        </div>
                    </div>
                </section>


                {/* Section 3: ChatGPT vs Gemini (Visual: Radar) */}
                <section id="chatgpt-vs-gemini" className="page__section section-grid">
                    <div className="section-grid__content">
                        <h2 className="page__section-title">Comparativa: ChatGPT vs Gemini</h2>
                        <article className="long-form-content">
                            <h3>Prop√≥sito de la Comparaci√≥n</h3>
                            <p>
                                En el dise√±o de sistemas de inteligencia legal, la elecci√≥n del modelo subyacente no es una preferencia de marca, sino una decisi√≥n de arquitectura. No se trata de determinar cu√°l herramienta es "mejor" en abstracto, sino de entender sus topolog√≠as cognitivas. ChatGPT (OpenAI) y Gemini (Google) representan dos filosof√≠as de procesamiento distintas: la primera orientada al razonamiento estructurado y la s√≠ntesis narrativa; la segunda, a la exploraci√≥n masiva de corpus y ventanas de contexto extendidas.
                            </p>
                            <p>
                                Para el profesional legal, entender esta distinci√≥n es la diferencia entre obtener una respuesta alucinada pero convincente, o un an√°lisis basado en datos concretos pero quiz√°s menos elocuente.
                            </p>

                            <h3>ChatGPT: Fortalezas y Limitaciones</h3>
                            <p>
                                <strong>El Motor de Razonamiento.</strong> La arquitectura de OpenAI (modelos o1/GPT-4) destaca por su capacidad de seguir instrucciones complejas (instruction following) y mantener coherencia l√≥gica en argumentos densos. Es ideal para tareas que requieren una estructura silog√≠stica fuerte: redactar una cl√°usula basada en tres condiciones previas, reformular un argumento defensivo o sintetizar un texto legal corto manteniendo un tono espec√≠fico.
                            </p>
                            <p>
                                Su limitaci√≥n principal en el √°mbito legal es la "miop√≠a de contexto". Aunque sus ventanas de contexto han crecido, su rendimiento se degrada cuando se le pide que analice cientos de documentos simult√°neamente. Tiende a "olvidar" detalles del medio del contexto (lost-in-the-middle phenomenon) y priorizar la informaci√≥n m√°s reciente, lo cual es fatal en una revisi√≥n de debida diligencia (due diligence) exhaustiva.
                            </p>

                            <h3>Gemini: Fortalezas y Limitaciones</h3>
                            <p>
                                <strong>El Motor de Exploraci√≥n.</strong> Gemini (particularmente los modelos Pro y Flash 1.5) ha sido dise√±ado para ventanas de contexto masivas (1M+ tokens). Esto cambia el paradigma: permite cargar un expediente judicial completo (cientos de PDFs, correos, audios) en una sola llamada (prompt). Su fortaleza no es necesariamente la redacci√≥n po√©tica, sino la "aguja en el pajar": encontrar esa contradicci√≥n espec√≠fica entre una declaraci√≥n de fojas 5 y un contrato de fojas 200.
                            </p>
                            <p>
                                Su limitaci√≥n radica a veces en la profundidad del razonamiento abstracto "zero-shot". Puede recuperar la informaci√≥n perfectamente, pero a veces requiere m√°s "mano guiada" (chain-of-thought prompting) para construir un argumento legal complejo a partir de esos datos sin caer en generalidades.
                            </p>

                            <h3>Diferencias Clave para An√°lisis Legal</h3>
                            <p>
                                <strong>Razonamiento vs. Exploraci√≥n:</strong> ChatGPT funciona mejor "pensando" sobre un texto limitado y curado. Gemini funciona mejor "leyendo" una biblioteca entera desordenada.
                                <br />
                                <strong>Profundidad vs. Amplitud:</strong> Si necesitas analizar la jurisprudencia de un solo fallo de la Corte Suprema en profundidad, usa ChatGPT. Si necesitas encontrar patrones en 50 fallos de tribunales inferiores, usa Gemini.
                                <br />
                                <strong>Coherencia Narrativa vs. Escaneo de Corpus:</strong> Para redactar el alegato final, ChatGPT. Para la etapa probatoria y discovery, Gemini.
                            </p>

                            <h3>Estrategia Multimodelo en Sistemas de Inteligencia</h3>
                            <p>
                                El error del novato es casarse con un solo modelo. Un Sistema de Inteligencia Legal robusto utiliza una estrategia de enrutamiento (model routing).
                            </p>
                            <p>
                                <em>Ejemplo de Flujo de Trabajo:</em>
                                1. <strong>Fase de Ingesta (Gemini):</strong> Se carga todo el expediente desordenado. Se le pide a Gemini que extraiga cronol√≥gicamente todos los hechos y cree un √≠ndice estructurado.
                                2. <strong>Fase de Orquestaci√≥n (C√≥digo/Agente):</strong> El sistema toma ese √≠ndice y separa los hechos relevantes de los irrelevantes.
                                3. <strong>Fase de An√°lisis (ChatGPT):</strong> El sistema env√≠a solo los hechos relevantes y disputados a ChatGPT para que redacte un an√°lisis de viabilidad de la demanda basado en la teor√≠a del caso.
                            </p>

                            <h3>Riesgos y Errores Comunes</h3>
                            <p>
                                Usar ChatGPT para leer expedientes enteros lleva a alucinaciones por desbordamiento de contexto: inventar√° fechas para llenar vac√≠os de memoria. Usar Gemini para redacci√≥n creativa legal sin supervisi√≥n puede resultar en textos secos o rob√≥ticos. El mayor riesgo es la falsa confianza: creer que porque el modelo resumi√≥ bien las primeras 10 p√°ginas, ley√≥ correctamente las otras 900. Sin validaci√≥n cruzada, esto es negligencia profesional tecnol√≥gica.
                            </p>

                            <h3>Casos de Uso Pr√°cticos</h3>
                            <p>
                                <strong>Preparaci√≥n de Caso:</strong> Subir toda la prueba documental a Gemini para generar una l√≠nea de tiempo interactiva.
                                <br />
                                <strong>An√°lisis de Jurisprudencia:</strong> Tomar los 3 fallos m√°s citados por la contraparte, pasarlos por ChatGPT para deconstruir sus argumentos l√≥gicos y encontrar falacias.
                                <br />
                                <strong>Investigaci√≥n Multicausa:</strong> Usar Gemini para buscar si un mismo actor ha iniciado demandas similares en distintas jurisdicciones (detectando "forum shopping") analizando m√∫ltiples PDFs de demandas simult√°neamente.
                            </p>

                            <h3>Implicancias Profesionales</h3>
                            <p>
                                La selecci√≥n correcta del modelo impacta directamente en la credibilidad. Un abogado que usa la herramienta incorrecta entregar√° trabajo con errores f√°cticos (por usar un modelo de razonamiento para b√∫squeda) o con argumentos pobres (por usar un modelo de b√∫squeda para argumentar). El "Ingeniero Legal" no "usa IA"; dise√±a el flujo de informaci√≥n eligiendo el procesador cognitivo adecuado para cada etapa del litigio.
                            </p>

                            <h3>Verificaci√≥n de Comprensi√≥n</h3>
                            <p><em>Responda para sus adentros o en sus notas personales:</em></p>
                            <ul>
                                <li><strong>Escenario 1:</strong> Tienes 400 correos electr√≥nicos desordenados entre tu cliente y un proveedor, y necesitas saber si en alguno de ellos se mencion√≥ expl√≠citamente la palabra "renuncia" antes de mayo de 2023. ¬øQu√© modelo usar√≠as y por qu√©?</li>
                                <li><strong>Escenario 2:</strong> Tienes un contrato de 5 p√°ginas y necesitas redactar una cl√°usula adicional que sea coherente con el estilo de redacci√≥n very formal y arcaico del resto del documento. ¬øCu√°l eliges?</li>
                                <li><strong>Escenario 3:</strong> Necesitas comparar las declaraciones de 5 testigos distintos (cada una de 20 p√°ginas) para encontrar contradicciones sutiles en los horarios que mencionan. ¬øEstrategia?</li>
                                <li><strong>Escenario 4:</strong> Est√°s construyendo un bot para responder preguntas sobre el reglamento interno de la empresa (un solo PDF de 50 p√°gs) para empleados. ¬øImporta m√°s la ventana de contexto o la capacidad de instrucci√≥n?</li>
                                <li><strong>Escenario 5:</strong> Quieres analizar si la sentencia que acabas de recibir (30 p√°gs) aplica correctamente un precedente de la Corte que tambi√©n tienes en PDF. ¬øC√≥mo orquestar√≠as esto?</li>
                            </ul>
                        </article>
                    </div>
                    {/* Visual Sidecar 2 */}
                    <div className="section-grid__visual">
                        <ModelComparisonChart />
                    </div>
                </section>

                <section id="system-architectures" className="page__section">
                    <h2 className="page__section-title">System Architectures</h2>
                    <article className="long-form-content">
                        <h3>Arquitecturas de Sistemas de IA Legal</h3>
                        <p>
                            Un sistema de inteligencia legal no es simplemente "usar ChatGPT". Es una arquitectura dise√±ada con capas espec√≠ficas que separan responsabilidades y garantizan calidad.
                        </p>

                        <h3>Arquitectura de 3 Capas</h3>
                        <ul>
                            <li><strong>Capa de Ingesta:</strong> Donde entran los documentos. Incluye OCR para documentos escaneados, extracci√≥n de texto de PDFs, y normalizaci√≥n de formatos.</li>
                            <li><strong>Capa de Procesamiento:</strong> Donde trabaja el modelo. Incluye prompts especializados, validaci√≥n de respuestas, y l√≥gica de negocios legal.</li>
                            <li><strong>Capa de Presentaci√≥n:</strong> Donde el profesional interact√∫a. Interfaces claras, citaci√≥n de fuentes, y herramientas de edici√≥n.</li>
                        </ul>

                        <h3>Patrones Comunes en Legal Tech</h3>
                        <p><strong>1. Patr√≥n de Pipeline Secuencial:</strong></p>
                        <p>Documento ‚Üí Extracci√≥n ‚Üí An√°lisis ‚Üí Validaci√≥n ‚Üí Salida formateada. Cada paso depende del anterior. Ideal para tareas predecibles como an√°lisis de contratos est√°ndar.</p>

                        <p><strong>2. Patr√≥n de Orquestador:</strong></p>
                        <p>Un "cerebro" central decide qu√© modelo usar para cada subtarea. Env√≠a res√∫menes a un modelo, an√°lisis profundo a otro, y combina resultados. Ideal para casos complejos.</p>

                        <p><strong>3. Patr√≥n de RAG (Retrieval-Augmented Generation):</strong></p>
                        <p>B√∫squeda en base documental + Generaci√≥n con contexto. El modelo no "sabe" tu jurisprudencia, pero la busca y la usa. Esencial para trabajo con precedentes.</p>

                        <h3>Consideraciones de Dise√±o</h3>
                        <ul>
                            <li><strong>Latencia:</strong> ¬øCu√°nto demora cada paso? En audiencias necesit√°s respuestas en segundos.</li>
                            <li><strong>Costo:</strong> Cada llamada al modelo tiene costo. Un sistema mal dise√±ado puede costar 10x m√°s.</li>
                            <li><strong>Auditabilidad:</strong> ¬øPod√©s rastrear de d√≥nde vino cada conclusi√≥n? Cr√≠tico para responsabilidad profesional.</li>
                            <li><strong>Escalabilidad:</strong> ¬øFunciona con 10 casos? ¬øCon 1.000?</li>
                        </ul>
                    </article>
                </section>

                <section id="validation-reasoning" className="page__section">
                    <h2 className="page__section-title">Validation & Reasoning Criteria</h2>
                    <article className="long-form-content">
                        <h3>La Validaci√≥n No Es Opcional</h3>
                        <p>
                            En derecho, un error no es solo inconveniente‚Äîpuede ser mala praxis. La validaci√≥n de salidas de IA debe ser <strong>sistem√°tica, no anecd√≥tica</strong>.
                        </p>

                        <h3>Criterios de Validaci√≥n para Trabajo Legal</h3>
                        <ul>
                            <li><strong>Verificabilidad f√°ctica:</strong> ¬øLas citas existen? ¬øLas fechas son correctas? ¬øLos art√≠culos citados dicen lo que el modelo afirma?</li>
                            <li><strong>Coherencia l√≥gica:</strong> ¬øLa conclusi√≥n se sigue de las premisas? ¬øHay saltos argumentales?</li>
                            <li><strong>Jurisdicci√≥n correcta:</strong> ¬øEl modelo mezcl√≥ derecho argentino con espa√±ol o mexicano?</li>
                            <li><strong>Vigencia normativa:</strong> ¬øLa ley o jurisprudencia citada sigue vigente?</li>
                            <li><strong>Completitud:</strong> ¬øEl an√°lisis cubre todos los aspectos relevantes o omiti√≥ algo cr√≠tico?</li>
                        </ul>

                        <h3>Protocolos de Verificaci√≥n</h3>
                        <p><strong>Nivel 1 - Chequeo R√°pido (5 minutos):</strong></p>
                        <ul>
                            <li>Verificar que las 3 primeras citas existan</li>
                            <li>Confirmar jurisdicci√≥n correcta</li>
                            <li>Leer conclusiones buscando contradicciones obvias</li>
                        </ul>

                        <p><strong>Nivel 2 - Revisi√≥n Est√°ndar (30 minutos):</strong></p>
                        <ul>
                            <li>Verificar TODAS las citas legales</li>
                            <li>Contrastar con fuentes primarias</li>
                            <li>Evaluar la estructura argumentativa</li>
                        </ul>

                        <p><strong>Nivel 3 - Auditor√≠a Completa (2+ horas):</strong></p>
                        <ul>
                            <li>Reconstrucci√≥n del razonamiento paso a paso</li>
                            <li>B√∫squeda de jurisprudencia contradictoria</li>
                            <li>Revisi√≥n por segundo profesional</li>
                        </ul>

                        <h3>Cu√°ndo Aplicar Cada Nivel</h3>
                        <ul>
                            <li><strong>Nivel 1:</strong> Borradores internos, notas de trabajo</li>
                            <li><strong>Nivel 2:</strong> Documentos para clientes, dict√°menes</li>
                            <li><strong>Nivel 3:</strong> Presentaciones judiciales, documentos p√∫blicos</li>
                        </ul>
                    </article>
                </section>

                {/* Section with Sticky Insight */}
                <section id="risks-errors" className="page__section section-grid">
                    <div className="section-grid__content">
                        <h2 className="page__section-title">Risks, Errors & Bad Practices</h2>
                        <article className="long-form-content">
                            <h3>Riesgos Cr√≠ticos en IA Legal</h3>

                            <h4>1. Alucinaciones Jur√≠dicas</h4>
                            <p>
                                El modelo puede inventar fallos, art√≠culos de ley, o doctrinas que suenan completamente plausibles pero no existen. Un fallo citado como "CSJN Fallos 340:1234" puede ser completamente ficticio.
                            </p>
                            <p><strong>Mitigaci√≥n:</strong> SIEMPRE verificar citas en fuentes primarias. Nunca confiar en una cita sin chequearla.</p>

                            <h4>2. Mezcla de Jurisdicciones</h4>
                            <p>
                                Entrenados con datos globales, los modelos mezclan frecuentemente conceptos de common law con derecho continental, o legislaci√≥n de distintos pa√≠ses hispanoparlantes.
                            </p>
                            <p><strong>Mitigaci√≥n:</strong> Especificar jurisdicci√≥n en CADA prompt. "Derecho argentino vigente" debe ser parte obligatoria del contexto.</p>

                            <h4>3. Desactualizaci√≥n Normativa</h4>
                            <p>
                                Los modelos tienen fecha de corte de conocimiento. Una ley derogada o modificada puede seguir siendo citada como vigente.
                            </p>
                            <p><strong>Mitigaci√≥n:</strong> Usar RAG con base normativa actualizada. No confiar en el conocimiento "interno" del modelo para vigencia.</p>

                            <h4>4. Falsa Confianza del Operador</h4>
                            <p>
                                El mayor riesgo no es t√©cnico sino humano: la tendencia a confiar excesivamente en respuestas elocuentes. Cuanto mejor "suena" una respuesta, m√°s peligrosa puede ser si est√° equivocada.
                            </p>
                            <p><strong>Mitigaci√≥n:</strong> Cultura de escepticismo sano. Tratar a la IA como un pasante muy capaz pero propenso a errores graves.</p>

                            <h3>Malas Pr√°cticas a Evitar</h3>
                            <ul>
                                <li><strong>Copy-paste sin revisi√≥n:</strong> Copiar directamente la salida del modelo a un documento judicial</li>
                                <li><strong>Un solo modelo para todo:</strong> Usar ChatGPT para expedientes de 500 p√°ginas cuando Gemini es m√°s apropiado</li>
                                <li><strong>Prompts vagos:</strong> "Analiz√° este contrato" sin especificar qu√© buscar</li>
                                <li><strong>Ignorar el contexto:</strong> No dar los hechos del caso antes de pedir an√°lisis</li>
                                <li><strong>No documentar el proceso:</strong> Si algo sale mal, ¬øpod√©s demostrar que hiciste verificaciones razonables?</li>
                            </ul>

                            <h3>Responsabilidad Profesional</h3>
                            <p>
                                La IA no reemplaza la responsabilidad del abogado. El C√≥digo de √âtica sigue aplicando: negligencia es negligencia, sea con libros o con algoritmos. El profesional firma, el profesional responde.
                            </p>
                        </article>
                    </div>
                    <div className="section-grid__visual">
                        <div className="visual-insight">
                            <h4>Insight Cr√≠tico</h4>
                            <p>La validaci√≥n no es opcional. Un sistema sin bucles de verificaci√≥n humana o algor√≠tmica es simplemente un generador de alucinaciones a escala industrial.</p>
                            <br />
                            <h4>Regla de Oro</h4>
                            <p>Si no pod√©s explicar c√≥mo llegaste a una conclusi√≥n sin mencionar "la IA me dijo", no est√°s listo para usarla profesionalmente.</p>
                        </div>
                    </div>
                </section>

                {/* Footer de navegaci√≥n */}
                <div className="unit-navigation">
                    <div className="unit-nav-prev">
                        {/* No hay unidad anterior */}
                    </div>
                    <div className="unit-status">
                        <span className="status-badge status-badge--current">üìñ Unidad Actual</span>
                    </div>
                    <div className="next-unit">
                        <span className="next-label">Pr√≥xima unidad:</span>
                        <Link to="/foundations-u2" className="next-title" style={{ color: 'inherit', textDecoration: 'none' }}>
                            Unidad 2 ‚Äì ChatGPT vs Gemini ‚Üí
                        </Link>
                    </div>
                </div>
            </div>
        </div>
    )
}

export default Foundations
